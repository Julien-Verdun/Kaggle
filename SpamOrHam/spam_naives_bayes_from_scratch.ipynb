{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Spam or Ham ?\n",
    "\n",
    "In this notebook, I will use the sms data from `spam-sms.csv` file in order to predict whether or not a sms is a spam or a ham. \n",
    "\n",
    "I implemented below the **naive bayes** method from scratch, without using any framework (sklearn for example).\n",
    "\n",
    "Julien Verdun\n",
    "07/12/2020"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import Counter \n",
    "import operator\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  target                                                sms\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>sms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "spam_df = pd.read_csv(\"spam-sms.csv\",header=0, encoding='latin-1',names=[\"target\",\"sms\",\"1\",\"2\",\"3\"])[[\"target\",\"sms\"]]\n",
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "spam_df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction of ham number in order to rebalance the dataset\n",
    "\n",
    "#spam_df = pd.concat([spam_df[spam_df[\"target\"]==\"ham\"].sample(frac=0.3,random_state=200),spam_df[spam_df[\"target\"]==\"spam\"]]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# spam_df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2vec(sentence,minimal_length=2):\n",
    "    \"\"\"\n",
    "    Transform a string sentence into a vector which includes the relevant words\n",
    "    \"\"\"\n",
    "    simplified_sentence = sentence.replace('\\W+',' ').replace('\\s+',' ').strip()\n",
    "    simplified_sentence = simplified_sentence.lower()\n",
    "    simplified_sentence = simplified_sentence.split(\" \")\n",
    "\n",
    "    vectorized_sentence = []\n",
    "    for word in simplified_sentence:\n",
    "        if len(word) >= minimal_length :\n",
    "            vectorized_sentence.append(word)\n",
    "    return vectorized_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  target                                                sms  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...   \n",
       "1    ham                      Ok lar... Joking wif u oni...   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3    ham  U dun say so early hor... U c already then say...   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                      vectorized_sms  \n",
       "0  [go, until, jurong, point,, crazy.., available...  \n",
       "1                  [ok, lar..., joking, wif, oni...]  \n",
       "2  [free, entry, in, wkly, comp, to, win, fa, cup...  \n",
       "3  [dun, say, so, early, hor..., already, then, s...  \n",
       "4  [nah, don't, think, he, goes, to, usf,, he, li...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>sms</th>\n      <th>vectorized_sms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>[go, until, jurong, point,, crazy.., available...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>[ok, lar..., joking, wif, oni...]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>[free, entry, in, wkly, comp, to, win, fa, cup...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>[dun, say, so, early, hor..., already, then, s...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>[nah, don't, think, he, goes, to, usf,, he, li...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# add to the dataframe a column vectorized_sms with the vector of words inside the sms\n",
    "spam_df[\"vectorized_sms\"] = spam_df[\"sms\"].apply(lambda x : sentence2vec(x))\n",
    "spam_df.head()"
   ]
  },
  {
   "source": [
    "Creation of the contingency matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word(sentence,minimal_length = 0):\n",
    "    \"\"\"\n",
    "    This function takes a sentence and returns a counter, i-e a dictionnary of words and occurences of those words in the sentence.   \n",
    "    \"\"\"\n",
    "    counter = Counter(sentence2vec(sentence))\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countVectorizer(list_words):\n",
    "    \"\"\"\n",
    "    This function takes a list of index corresponding to the training request sentences we want to use, and a number, corresponding to the length of the output, and computes a dictionnary of most recurrent words and another one of most frequent words.   \n",
    "    \"\"\"\n",
    "    # initialisation of the counter of occurencies\n",
    "    word_counters = Counter()\n",
    "    # list for storing the number of words in every sentences\n",
    "    list_len_sentences = []\n",
    "    # for each index in the given list\n",
    "    for index in range(len(list_words)):\n",
    "        # we count the number of occurences of words in the sentence (after having clean it up)\n",
    "        counter = count_word(list_words[index])\n",
    "        # we fill in the list of sentences' length\n",
    "        list_len_sentences.append(sum(counter.values()))\n",
    "        # we concatenate the occurency and frequency counters \n",
    "        word_counters = word_counters + counter\n",
    "\n",
    "    word_sorted = sorted(\n",
    "        word_counters.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    return dict(word_counters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(spam_df,X_fold_split,test_index):\n",
    "    \"\"\"\n",
    "    This function takes the dataframe spam_df and a list of indexes inside each fold X_fold_split, the index of the fold considered as the test fold, and returns a testing set with the data considered as testing set and a training set with the other folds. \n",
    "    \"\"\"\n",
    "    test_set = spam_df.loc[X_fold_split[test_index]]\n",
    "    train_set = []\n",
    "    for i in range(10):\n",
    "        if i != test_index:\n",
    "            train_set.append(spam_df.loc[X_fold_split[i]])\n",
    "    train_set = pd.concat(train_set)\n",
    "    return train_set.reset_index(drop=True),test_set.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of being a spam\n",
    "p_spam = spam_df[\"target\"].value_counts()[\"spam\"]/np.sum(spam_df[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lissage_laplace(spam_count,ham_count):\n",
    "    \"\"\"\n",
    "    This function computes the probabilities of every word inside spam_count and ham_count using the number of occurencies of each word, the total number of words, the laplace_constante\n",
    "    The \"Lissage de Laplace\" prevents from null probabilities \n",
    "    \"\"\"\n",
    "    spam_total_occ = sum(spam_count.values())\n",
    "    ham_total_occ = sum(ham_count.values())\n",
    "    laplace_constante = len(Counter(spam_count)+Counter(ham_count))\n",
    "    spam_proba={}\n",
    "    ham_proba={}\n",
    "    for word in spam_count:\n",
    "        spam_proba[word] = (spam_count[word]+1)/(spam_total_occ+laplace_constante) \n",
    "    for word in ham_count:\n",
    "        ham_proba[word] = (ham_count[word]+1)/(ham_total_occ+laplace_constante)\n",
    "\n",
    "    return spam_proba,ham_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesClassifier(spam_proba,ham_proba,sentence,p_spam):\n",
    "    \"\"\"\n",
    "    This function predicts for a given sentence whether or not it is a spam with naives Bayes method.\n",
    "    \"\"\"\n",
    "    spam_score = 1\n",
    "    ham_score = 1\n",
    "    vectorizedSentence = count_word(sentence)\n",
    "    for word in dict(vectorizedSentence):\n",
    "        if word in spam_proba:\n",
    "            spam_score *= spam_proba[word]**vectorizedSentence[word]\n",
    "        if word in ham_proba:\n",
    "            ham_score *= ham_proba[word]**vectorizedSentence[word]\n",
    "\n",
    "    if spam_score*p_spam > ham_score*(1-p_spam):\n",
    "        return 1 \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_nbclf(spam_proba,ham_proba,test_df, p_spam):\n",
    "    \"\"\"\n",
    "    This function creates the confusion matrix of the model with the test_df data\n",
    "    \"\"\"\n",
    "    conf_mat = np.zeros((2,2))\n",
    "    for i in range(test_df[\"sms\"].shape[0]):\n",
    "        is_spam = naiveBayesClassifier(spam_proba,ham_proba,test_df[\"sms\"][i], p_spam)\n",
    "        if test_df[\"target\"][i] == \"spam\":\n",
    "            conf_mat[1][1-is_spam] += 1\n",
    "        else :\n",
    "            conf_mat[0][1-is_spam] += 1\n",
    "    return conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(conf_matrix):\n",
    "    \"\"\"\n",
    "    This function computes the following metrics : accuracy, precision, recall and F-measure as follow :\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    P = Tp/(Tp+Fp)\n",
    "    R = Tp/(Tp+Fn)\n",
    "    \"\"\"\n",
    "    A = np.round(np.sum(np.diag(conf_matrix))/np.sum(conf_matrix),2)\n",
    "    P = conf_matrix[0][0]/ (conf_matrix[0][0] + conf_matrix[0][1])\n",
    "    R = conf_matrix[0][0]/ (conf_matrix[0][0] + conf_matrix[1][0])\n",
    "    F1 = np.round(2*P*R/(P+R),2)\n",
    "    return A, F1, np.round(P,2) ,np.round(R,2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_fold_cross_validation(spam_df,n_folds=10,p_spam=p_spam):\n",
    "    \"\"\"\n",
    "    This function makes a X-fold cross-validation on spam_df data and returns for each metrics a list of performances per fold.\n",
    "    \"\"\"\n",
    "    A = []\n",
    "    F1 = []\n",
    "    P = []\n",
    "    R = []\n",
    "    X_fold_split = np.array_split(spam_df.index, n_folds)\n",
    "    print(\"----- TRAINING -----\")\n",
    "    for i in range(n_folds):\n",
    "        train_df,test_df = train_test_split(spam_df,X_fold_split,i)\n",
    "        spam_count = countVectorizer(np.array(train_df[train_df[\"target\"]==\"spam\"][\"sms\"].values))\n",
    "        ham_count = countVectorizer(np.array(train_df[train_df[\"target\"]==\"ham\"][\"sms\"].values))\n",
    "        spam_proba,ham_proba = lissage_laplace(spam_count,ham_count)\n",
    "        conf_mat = confusion_matrix_nbclf(spam_proba,ham_proba,test_df, p_spam)\n",
    "        Ai, F1i, Pi ,Ri = f1_score(conf_mat)\n",
    "        A.append(Ai)\n",
    "        F1.append(F1i)\n",
    "        P.append(Pi)\n",
    "        R.append(Ri)\n",
    "        print(\"Fold {} : acc {} ; F1 {} ; P {} ; R {}\".format(i,Ai,F1i,Pi,Ri))\n",
    "    return A,F1,P,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----- TRAINING -----\n",
      "Fold 0 : acc 0.87 ; F1 0.92 ; P 0.87 ; R 0.98\n",
      "Fold 1 : acc 0.88 ; F1 0.92 ; P 0.88 ; R 0.97\n",
      "Fold 2 : acc 0.86 ; F1 0.92 ; P 0.87 ; R 0.97\n",
      "Fold 3 : acc 0.88 ; F1 0.93 ; P 0.87 ; R 0.99\n",
      "Fold 4 : acc 0.86 ; F1 0.91 ; P 0.86 ; R 0.97\n",
      "Fold 5 : acc 0.86 ; F1 0.92 ; P 0.87 ; R 0.98\n",
      "Fold 6 : acc 0.87 ; F1 0.92 ; P 0.88 ; R 0.98\n",
      "Fold 7 : acc 0.88 ; F1 0.93 ; P 0.89 ; R 0.97\n",
      "Fold 8 : acc 0.86 ; F1 0.91 ; P 0.86 ; R 0.97\n",
      "Fold 9 : acc 0.88 ; F1 0.93 ; P 0.88 ; R 0.98\n"
     ]
    }
   ],
   "source": [
    "A,F1,P,R = X_fold_cross_validation(spam_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----- TEST -----\n\nAccuracy :  87.0 \nF1-score :  92.1 \nPrecision :  87.3 \nRecall :  97.6\n"
     ]
    }
   ],
   "source": [
    "print(\"----- TEST -----\")\n",
    "print(\"\\nAccuracy : \",np.round(100*np.mean(A),3),\"\\nF1-score : \",np.round(100*np.mean(F1),3),\"\\nPrecision : \",np.round(100*np.mean(P),3),\"\\nRecall : \",np.round(100*np.mean(R),3))"
   ]
  },
  {
   "source": [
    "The **Naive Bayes** method implemented from scartch reached an accuracy of 87% with a good F-measure of 92.1%. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}