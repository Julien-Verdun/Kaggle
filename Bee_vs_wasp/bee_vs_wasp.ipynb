{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":["import tensorflow as tf\n","import pandas as pd\n","from tensorflow.keras import datasets, layers, models, preprocessing\n","import matplotlib.pyplot as plt\n","import PIL\n","from PIL import Image\n","import numpy as np\n","import os\n","from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# project parameters\n","IMAGE_SIZE = 256\n","EPOCHS = 15\n","BATCH_SIZE = 32\n","ROOT = \"./src/\"#\"../input/bee-vs-wasp/kaggle_bee_vs_wasp/\""],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Image processing\n","\n","First, I will load the images, resize the image and normalize them. Then, I will split the dataset into two sets, the training and test set.  "]},{"metadata":{"trusted":true},"cell_type":"code","source":["df = pd.read_csv(ROOT+\"labels.csv\")\n","df.head()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# # we only keep photo with a quality equals to 1\n","# df = df.query('photo_quality == 1').reset_index(drop=True)\n","# df.head()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# change \\ in path to /\n","for idx in tqdm(df.index):\n","    df.loc[idx,'path']=df.loc[idx,'path'].replace('\\\\', '/')\n","\n","df.head()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# number of image in every labels\n","number_per_label = df['label'].value_counts()\n","print(number_per_label)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["plt.hist(list(number_per_label.index), bins=[k for k in range(len(number_per_label.values)+1)],weights=number_per_label.values, rwidth=0.9, align='left')\n","plt.xlabel('Type of image')\n","plt.ylabel('Number of image')\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["The dataset already includes the training data, validation data and final validation data.\n","\n","Below, I split the dataframe regarding those properties."]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_df = df.query('is_validation == 0 & is_final_validation == 0').reset_index(drop=True)\n","val_df = df.query('is_validation == 1').reset_index(drop=True)\n","test_df = df.query('is_final_validation == 1').reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(\"Taining set : \\n\",train_df['label'].value_counts())\n","print(\"\\nValidation set : \\n\",val_df['label'].value_counts())\n","print(\"\\nFinal validation set : \\n\",test_df['label'].value_counts())"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Our datasets are not balanced, there are way more wasp images than 'other' images. \n","In a first attempt, we will consider the dataset balanced. \n","\n","Let's plot some images"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# let's see some bee images\n","plt.figure()\n","for i in range(1,10):\n","    im = Image.open(ROOT + df.query('label==\"bee\"')['path'].reset_index(drop=True)[i-1],mode=\"r\")\n","    im = np.array(im)/255\n","    plt.subplot(3,3,3*(i//3)+i%3)\n","    plt.axis('off')\n","    plt.imshow(im)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# let's see some wasp images\n","plt.figure()\n","for i in range(1,10):\n","    im = Image.open(ROOT + df.query('label==\"wasp\"')['path'].reset_index(drop=True)[i-1],mode=\"r\")\n","    im = np.array(im)\n","    plt.subplot(3,3,3*(i//3)+i%3)\n","    plt.axis('off')\n","    plt.imshow(im)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# let's see some other insect images\n","try:\n","    plt.figure()\n","    for i in range(1,10):\n","        im = Image.open(ROOT + df.query('label==\"insect\"')['path'].reset_index(drop=True)[i-1],mode=\"r\")\n","        im = np.array(im)\n","        plt.subplot(3,3,3*(i//3)+i%3)\n","        plt.axis('off')\n","        plt.imshow(im)\n","except:\n","    print(\"No image\")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# let's see some other images\n","try :\n","    plt.figure()\n","    for i in range(1,10):\n","        im = Image.open(ROOT + df.query('label==\"other\"')['path'].reset_index(drop=True)[i-1],mode=\"r\")\n","        im = np.array(im)\n","        plt.subplot(3,3,3*(i//3)+i%3)\n","        plt.axis('off')\n","        plt.imshow(im)\n","except:\n","    print(\"No image\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["In order to train a machine learning algorithm on those data, I will first create the 3 datasets :\n","- training set\n","- validation set\n","- final validation set.\n","\n","\n","The datasets will be composed of the processed images and the labels."]},{"metadata":{"trusted":true},"cell_type":"code","source":["# data loader\n","train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rescale=1./255\n",")\n","\n","val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rescale=1./255\n",")\n","val_fin_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rescale=1./255\n",")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_generator = train_datagen.flow_from_dataframe(\n","            train_df, \n","            directory=ROOT, \n","            x_col='path', \n","            y_col='label',\n","            classes=['bee','wasp','insect','other'],\n","            target_size=(IMAGE_SIZE, IMAGE_SIZE), \n","            batch_size=BATCH_SIZE, \n","            shuffle=True, \n","            seed=123\n","        )\n","validation_generator = val_datagen.flow_from_dataframe(\n","            val_df, \n","            directory=ROOT, \n","            x_col='path', \n","            y_col='label',\n","            classes=['bee','wasp','insect','other'],\n","            target_size=(IMAGE_SIZE, IMAGE_SIZE), \n","            batch_size=BATCH_SIZE, \n","            shuffle=True, \n","            seed=123\n","        )\n","validation_finale_generator = val_fin_datagen.flow_from_dataframe(\n","            test_df, \n","            directory=ROOT, \n","            x_col='path', \n","            y_col='label',\n","            classes=['bee','wasp','insect','other'],\n","            target_size=(IMAGE_SIZE, IMAGE_SIZE), \n","            batch_size=BATCH_SIZE, \n","            shuffle=True, \n","            seed=123\n","        )"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["ROTATION = 0.2\n","ZOOM = 0.2\n","CONTRAST = 0.2\n","\n","data_augmentation = tf.keras.Sequential(\n","  [\n","    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\", input_shape=(IMAGE_SIZE,IMAGE_SIZE,3)),\n","    layers.experimental.preprocessing.RandomRotation(ROTATION),\n","    layers.experimental.preprocessing.RandomZoom(ZOOM),\n","    #layers.experimental.preprocessing.RandomContrast([1-CONTRAST, 1+CONTRAST])\n","  ]\n",")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["model = models.Sequential(data_augmentation)\n","model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.summary()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["layers.Dropout(0.2)\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation='relu'))\n","layers.Dropout(0.2)\n","model.add(layers.Dense(32, activation='relu'))\n","model.add(layers.Dense(4,activation='softmax'))\n","model.summary()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["model.compile(optimizer='adam',\n","            loss=tf.keras.losses.CategoricalCrossentropy(),\n","            metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["tf.debugging.set_log_device_placement(True)\n","\n","# Place tensors on the CPU\n","with tf.device('/:GPU:0'):    \n","    history = model.fit_generator(\n","        train_generator, \n","        steps_per_epoch=200,\n","        epochs=EPOCHS,\n","        validation_data=validation_generator,\n","        validation_steps=100\n","    )"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["test_loss, test_acc = model.evaluate(validation_finale_generator, verbose=2)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Confusion matrix"]},{"metadata":{"trusted":true},"cell_type":"code","source":["confusion_matrix = tf.math.confusion_matrix(\n","    validation_finale_generator.classes, np.argmax(model.predict(validation_finale_generator), axis=1)\n",")\n","print(confusion_matrix)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(np.diag(confusion_matrix))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["good_prediction = np.sum(np.diag(confusion_matrix))\n","wrong_prediction = np.sum(confusion_matrix) - good_prediction\n","\n","print(\"Good prediction : \", good_prediction)\n","print(\"Wrong prediction : \", wrong_prediction)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### AUC-ROC score and ROC-curve\n"]},{"metadata":{"trusted":true},"cell_type":"code","source":[],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Test of this model on some images"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def get_image(df,path,image_size=IMAGE_SIZE):\n","    \"\"\"\n","    This function takes a dataframe df and returns the image with path 'path' after processing it  \n","    \"\"\"\n","    idx = df['path'][df['path']==path].index.tolist()[0]\n","    im = np.array(Image.open(ROOT+df['path'][idx], mode='r'))/255\n","    label = df['label'][idx]\n","    try:\n","        im = tf.image.resize(im, (image_size,image_size), method=tf.image.ResizeMethod.BILINEAR, preserve_aspect_ratio=False, antialias=False, name=None)\n","    except :\n","        # if the image is a grayscale\n","        im_3d = np.zeros((im.shape[0],im.shape[1],3))\n","        for i in range(im.shape[0]):\n","            for j in range(im.shape[1]):\n","                im_3d[i,j,:] = im[i,j]\n","        im = tf.image.resize(im_3d, (image_size,image_size), method=tf.image.ResizeMethod.BILINEAR, preserve_aspect_ratio=False, antialias=False, name=None)\n","    return im, label"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def prediction(model,df,list_path):\n","    \"\"\"\n","    This functions takes the trained model and a list of paths and returns\n","    the list of predicted label for the images corresponding th the paths.\n","    It plots every images with the prediction\n","    \"\"\"\n","    label = [\"bee\",\"wasp\",\"insect\",\"other\"]\n","    plt.figure()\n","    images = []\n","    list_true = []\n","    list_prediction = []\n","    for path in list_path:\n","        im, lbl = get_image(df,path)\n","        images.append(im)\n","        list_true.append(lbl)        \n","    for lbl in np.argmax(model.predict(np.array(images)),axis=1):\n","        list_prediction.append(label[lbl])\n","        \n","    for i in range(len(list_true)):\n","        if i >= 9:\n","            break\n","        plt.subplot(3,3,3*((i+1)//3)+(i+1)%3)\n","        plt.axis('off')\n","        plt.imshow(images[i])\n","        plt.title(list_prediction[i] + \" - \" + list_true[i])\n","    \n","    plt.show()\n","        \n","    return list_true,list_prediction"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["prediction(model,df,['bee1/1240800_e5f2b40032_n.jpg',\n","                     'other_noinsect/521021.jpg',\n","                     'other_noinsect/521697.jpg',\n","                     'other_insect/5826066_3071dcf48f_n.jpg',\n","                     'other_insect/7091961939_f90294ee2e_w.jpg'\n","                    ]\n","          )"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Conclusion of the CNN\n","\n","Accuracy : 80%\n"]}],"metadata":{"kernelspec":{"name":"Python 3.7.9 64-bit","display_name":"Python 3.7.9 64-bit","metadata":{"interpreter":{"hash":"c38df42a44b20c43d55ef93063a6a1526caabf3e59bc32fe365dbbb00d95769f"}}},"language_info":{"name":"python","version":"3.7.9-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}